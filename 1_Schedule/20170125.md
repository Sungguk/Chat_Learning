<< 20170125 / Wed>>

1. Machine Network for one shot learning - 이금재님
- CNN이 seq2seq 역할을 함
- CNN에서 사진을 거치면서 사진의 사이즈는 작아진다. 마지막에 벡터로 쭉 나열되고 그 안에서 순서는 상관없음. 여러장을 거치면서 대표 이미지가 나오는것 이것으로 classifier
- 여기에서는 classifier만 띄어낸 상태의 CNN
- 학습과 입력이미지의 CNN은 같은 모델을 사용함.

- CNN -> KNN
CNN으로 feature(특징)을 뽑아서 언어처리 가능 -  sequence 개념이 나옴
여러장의 이미지 sequence (순서의 개념이 들어간 것)

- 일반 KNN
: 매트릭 공간에 임베딩되어 두 점의 사이의 거리를 구함.
- 가중 KNN
: weight를 더해줌.

각각의 요소들이 패러다임에 묶일 수 있음.
- metric learning : 거리로 학습 = KNN
- 외부 메모리 Augmented
  VGG를 이용함 : 외부메모리로 봄.
  CNN으로 학습된 모든 메모리는 외부메모리라고 볼 수 잇음
- LSTM 두 가지 쓰임
  일반
  BI-DIRECTIONAL : 양방향에서 하기 때문에 순서는 중요하지 않고

LSTM 을 넣은 이유는?
Reference 논문 : Set to Set 읽고 보면 one shot learning에 대한 이해가 더 잘됨.
활용 분야 : 필체인식, 언어 작업

페이페이리 동영상 : 아이가 기계보다 동물을 더 잘 맞춘다. (아이는 아는 것이 많지 않기 떄문에)
https://www.ted.com/talks/fei_fei_li_how_we_re_teaching_computers_to_understand_pictures?language=ko

Attention Kernel
- softmax , cosine similarlity
- attention도 학습되는 것 - 가중치를 주기 위함

가중 KNN
: Data들이 겹쳐서 분포 될때 이것을 해결하려면 다시 feature부터 뽑고 해야하는데 이것을 피하기 위해서
 + Attention 가중치를 줘서 분리해서 이웃 사이의 거리를 확실히 구분되게끔 해서 입력 이미지를 넣었을때 가까운 이미지를 구하기 위함.
one shot learning 에서는 Model을 수정하지 않음.

2. 신성진님
나라면 이런 영어 챗봇을 만들고 싶다.
브레인 스토밍 해보기

3. CS224d - TensorFlow - 김진원님
- Tensorflow의 대한 기본 개념
- 함수 설명
- Initial Variable 함수 변경됨.
- Linear Regreesion
- TensorBoard - API들이 신규로 다 바뀜
