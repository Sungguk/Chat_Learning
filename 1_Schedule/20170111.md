1. Lecture5. Project Information + Neural Networks & Backprop (백병인님)
- Backpropagation 얘기
- coursera :
- cs231n : 실용적, 예제, 수학적 의미, 필드에서 사용할 수 있는, 가장 좋은 것 같음
  Backproppagation : http://cs231n.github.io/optimization-2/#staged
- cs224d : 코세라보단 불친절
- Lecture 3 Note 보면 도움됨.
http://cs224d.stanford.edu/lecture_notes/notes3.pdf


2. Glove Source - 2 (전수진님)
- AdaGrad : Sparse한 Weight의 업데이트에 좋은 optimizer / SGD에서 Learning Rate를 제거하는 방법
https://xcorr.net/2014/01/23/adagrad-eliminating-learning-rates-in-stochastic-gradient-descent/
- Learning Rate를 학습시키자는 논문 : https://arxiv.org/abs/1606.04474

3. Neural Variational Inference for Text Processing 소스 및 논문 소개 (전창욱님)
- 해당 논문은 베이지안 추론을 활용해서 wiki 백과에 있는 데이터를 기준으로 Q이 input 되었을때, Answer를 추출해 주는 논문 인것 같음.
- 해당 소스는 김태훈님이 자체로 짠 소스로 논문에서 나온 Question을 넣어도 Answer가 안나오는 것으로 보아 분석 안하는게 좋아보임..

4. 김진원님
분배되는 전력의 패턴을 보고 이것을 모으면 엄청 빅데이터가 되니
패턴을 분석해서 휴일/평일/밤.. 등등 상업/가정 등등의 이런 것들을
이상징후를 파악해서 서비스 해주는 것

한전이나 발전소를 지으려면 돈이 많이 드니 전기를 효율적으로 사용할 수 있게끔
전력을 모아놧다 peak 시간대에 사용하게끔 해서 분배해주는 것
